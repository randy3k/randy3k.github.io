---
layout: page
title: Research 
---


<ul class="nav nav-tabs">
  <li class="active"><a href="#">Interests</a></li>
  <li><a href="publications/">Publications</a></li>
</ul>

<br>

My research interests span a number of fields in Statistics. Loosely speaking, they can be divided into three categories: generalized fiducial inference, analysis of high dimensional and massive data, and signal and image processing.

###  Generalized Fiducial Inference

The origin of Fiducial inference can be traced back to R.A. Fisher (Fisher, 1935), who introduced the concept of a fiducial distribution of a parameter and proposed the use of this fiducial distribution, in place of the Bayesian posterior distribution, for interval estimation of the parameter. Since then, it has been a subject of many discussions and controversies for its non- exactness and non-uniqueness properties. Consequently, the fiducial approach fell into disfavor and became a topic of historical interest only. In 1990s, Tsui and Weerahandi (1989) and Weerahandi (1993) have presented a series of papers on generalized confidence intervals. Later, Hannig et al. (2006) pointed out that there was a connection between fiducial arguments and generalized confidence intervals. Evolving through a series of works in 2000s (e.g., Hannig, 2009; Hannig and Lee, 2009), the idea is now known as generalized fiducial inference (GFI), which is a general methodology for constructing a distribution on model parameter(s) without the use of any prior distribution. The resulting distribution is called the generalized fiducial distribution, which can be applied to form estimates and confidence intervals for the model parameter(s). Previous studies have shown that such estimates and confidence intervals possess excellent frequentist properties (e.g., Hannig et al., 2006; Hannig, 2009; Hannig and Lee, 2009).


### Analysis of massive and high dimensional data

The ultrahigh dimensional linear regression problem has attracted a lot of recent attentions from the research community. Most of the published work are concerned with the selection and estimation of the significant variables under the sparsity assumption. I and my collaborators (Lai et al., 2014) have studied another important aspect of the ultrahigh dimensional regression problem, namely, uncertainty quantification. To be more specific, we proposed methods for deriving a probability density function on the set of all possible models, which allows us to construct confidence intervals for the corresponding parameters. These proposed methods are developed using GFI. We also stud- ied the theoretical properties of the proposed methods, and in particular it is shown that statistical inference based on the proposed methods will have exact frequentist property for the ultrahigh dimensional regression problem. In terms of empirical performances, simulation experiments show that the proposed methods are capable of producing confidence intervals with correct nominated coverage. This work has been accepted by JASA for publication.

###  Signal and image processing

#### Nonparametric cepstrum estimation via optimal risk smoothing

I and my collaborators (Lai et al., 2010) proposed a nonparametric cepstrum estimation procedure that is capable of producing smoother and more accurate cepstrum estimates. The Steins unbiased risk estimation (SURE) approach is adopted to select the turning parameters. We showed that the use of this SURE selection method for this problem is asymptotically optimal under suitable regularity conditions.

#### Signal segmentation

I and my collaborators (Wong et al., 2010) considered the problem of partitioning a non-stationary signal sequence into a set of stationary signal sub-sequences, which can be adequately modeled by a superposition of different sinusoids. We reformulated the problem as a statistical model selection problem, and adopted the minimum description length principle to construct estimators of parameters. These estimators are optimizers of an objective function, which is non-convex and hard to be optimized. A genetic algorithm is developed for solving the difficult optimization problem.

----

Conducting researches is always an excitement to me. I am ready to dedicate myself to be an active and effective researcher.
