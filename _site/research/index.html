<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>Research - RTalks.net</title>

<meta name="author" content="Randy Lai">

<!-- Enable responsive viewport -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->

<link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
<!-- <link href="//netdna.bootstrapcdn.com/bootstrap/3.0.2/css/bootstrap.min.css" rel="stylesheet"> -->
<link href="/assets/css/bootstrap.css" rel="stylesheet" type="text/css" media="all">
<link href="/assets/css/pygments.css" rel="stylesheet" type="text/css" media="all">
<link href="/assets/css/style.css" rel="stylesheet" type="text/css" media="all">

<script src="http://code.jquery.com/jquery-1.9.1.js"></script>
<script src="//netdna.bootstrapcdn.com/bootstrap/3.0.2/js/bootstrap.min.js"></script>  
<script>
  (function() {
    var cx = '008225976323914720770:ha27dsnxije';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//www.google.com/cse/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
</head>
<body>   
        <div class="navbar navbar-default navbar-static-top" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>         
                <div><a href="/" class="navbar-brand">RTalks.net</a></div>
            </div>
            <div class="collapse navbar-collapse" id="navbar-collapse-1">
                <ul class="nav navbar-nav">
                         
                    <li class="active"><a href="/research/">Research</a></li>
                      
                    <li ><a href="/apps/">Apps</a></li>
                      
                    <li ><a href="/blog/">Blog</a></li>
                      
                </ul>
            </div>
        </div>
    </div>
    <div class="jumbotron">
        <div class="container">
            <h1>
            <span class="fa fa-code"></span> Research 
            </h1>
            
        </div>
    </div>
    <div class="container">
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-9 col-lg-9 maincontent">
                    <ul class="nav nav-tabs">
  <li class="active"><a href="#">Interests</a></li>
  <li><a href="publications/">Publications</a></li>
</ul>

<p><br /></p>

<p>My research interests span a number of fields in Statistics. Loosely speaking, they can be divided into three categories: generalized fiducial inference, analysis of high dimensional and massive data, and signal and image&nbsp;processing.</p>

<h3 id="generalized-fiducial-inference">Generalized Fiducial&nbsp;Inference</h3>

<p>The origin of Fiducial inference can be traced back to <span class="caps">R.A.</span> Fisher (Fisher, 1935), who introduced the concept of a fiducial distribution of a parameter and proposed the use of this fiducial distribution, in place of the Bayesian posterior distribution, for interval estimation of the parameter. Since then, it has been a subject of many discussions and controversies for its non-exactness and non-uniqueness properties. Consequently, the fiducial approach fell into disfavor and became a topic of historical interest only. In 1990s, Tsui and Weerahandi (1989) and Weerahandi (1993) have presented a series of papers on generalized confidence intervals. Later, Hannig et al. (2006) pointed out that there was a connection between fiducial arguments and generalized confidence intervals. Evolving through a series of works in 2000s (e.g., Hannig, 2009; Hannig and Lee, 2009), the idea is now known as generalized fiducial inference (<span class="caps">GFI</span>), which is a general methodology for constructing a distribution on model parameter(s) without the use of any prior distribution. The resulting distribution is called the generalized fiducial distribution, which can be applied to form estimates and confidence intervals for the model parameter(s). Previous studies have shown that such estimates and confidence intervals possess excellent frequentist properties (e.g., Hannig, 2009; Hannig and Lee, 2009; Hannig et al.,&nbsp;2006).</p>

<h4 id="computational-issues-of-gfi">Computational issues of&nbsp;<span class="caps">GFI</span></h4>

<p>For some problems, the corresponding generalized fiducial distribution can be analytically derived, while for some other problems its exact form is unknown or algebraically hard to obtain. I and my collaborators (Hannig et al., 2013) proposed a new computational method for conducting generalized fiducial inference without the need to derive the exact closed form of the generalized fiducial distribution. It is shown that this computational method enjoys desirable theoretical and empirical properties. As a result, the proposed method widely enhances the applicability of generalized fiducial&nbsp;inference.</p>

<h4 id="further-research-higher-order-asymptotic-properties-of-gfi">Further research: higher order asymptotic properties of&nbsp;<span class="caps">GFI</span></h4>

<p>Hannig (2009) has established that the validity of Bernstein-von Mises theorem for the <span class="caps">GFI</span> under certain regular conditions. Bernstein-von Mises theorem states that, as sample size increases, any well behaved Bayesian posterior converges to a normal distribution. However, there are still some theoretical properties of <span class="caps">GFI</span> are not yet known or have not been studied. I plan to investigate higher order asymptotic properties of <span class="caps">GFI</span> by means of Cornish-Fisher expansion and Edgeworth expansion. If successful, this will resolve an important open issue of <span class="caps">GFI</span>: the choice of so called data generating equation. It will also help understanding the similarities and differences between <span class="caps">GFI</span> and other related interval estimation methodologies such as Bootstrapping. More applications of <span class="caps">GFI</span> can be found in next&nbsp;section.</p>

<h3 id="analysis-of-massive-and-high-dimensional-data">Analysis of massive and high dimensional&nbsp;data</h3>

<h4 id="gfi-for-ultrahigh-dimensional-regression"><span class="caps">GFI</span> for Ultrahigh Dimensional&nbsp;Regression</h4>

<p>The ultrahigh dimensional linear regression problem has attracted a lot of attentions from the research community in the last decade. Most of the published work are concerned with the selection and estimation of the significant variables under the sparsity assumption. I and my collaborators (Lai et al., 2013) have studied another important aspect of the ultrahigh dimensional regression problem, namely, uncertainty quantification. To be more specific, we proposed methods for deriving a probability density function on the set of all possible models, which allows us to construct confidence intervals for the corresponding parameters. These proposed methods are developed using <span class="caps">GFI.</span> We also studied the theoretical properties of the proposed methods, and in particular it is shown that statistical inference based on the proposed methods will have exact frequentist property for the ultrahigh dimensional regression problem. In terms of empirical performances, simulation experiments show that the proposed methods are capable of producing confidence intervals with correct nominated&nbsp;coverage.</p>

<h4 id="variable-selection-for-additive-mixed-models">Variable selection for additive mixed&nbsp;models</h4>

<p>Additive mixed models (AMMs) are an extension of additive models that incorporates random effects. I and my collaborators (Lai et al., 2012) considered the problem of model selection in a nonparametric additive mixed modeling framework in the so-called “large p small n” context. Estimation and selection of such nonparametric fixed effects are simultaneously achieved by using the adaptive group lasso method (Meier et al., 2008), while the random effects are selected by a classical backward selection procedure. We applied Bayesian Information criterion (<span class="caps">BIC</span>) to facilitate the automatic selection of model dimension. It is shown that, theoretically this <span class="caps">BIC</span> model selection method possesses the so-called oracle property, while computationally a practical algorithm is developed for solving the optimization problem&nbsp;involved.</p>

<h4 id="proposed-research-gfi-for-massive-data">Proposed research: <span class="caps">GFI</span> for massive&nbsp;data</h4>

<p>Technology advances allow faster computation, as well as data collection with larger and larger sizes. For example, sequencing in genetics would easily produce terabytes of information in a single experiment. The so-called “Divide and conquer” strategy has made a huge success in analysis of massive datasets. Parallel computing is often employed to increase the efficiency of such strategy. <span class="caps">GFI</span> is particularly well suited for such divide and conquer strategy. I am investigating the use of <span class="caps">GFI</span> to develop a statistical consistent and computationally practical method for dividing the data and combining the information. Preliminary studies show that our proposed methodology is extremely promising. I also plan to study the theoretical properties for such&nbsp;strategy.</p>

<h4 id="proposed-research-fiducial-selector">Proposed research: Fiducial&nbsp;selector</h4>

<p><span class="caps">LASSO</span> type algorithms have been very popular in the last decade for its ability to select significant predictors. Some of these methods have been combined with Bayesian philosophy. However, a common issue for these approaches is that it is the point estimator, such as the posterior mode, that enjoys sparsity, while the posterior distribution is not sparse. I have done some initial investigation to modify generalized fiducial distribution so that it would produce a sparse distribution. Such a sparse distribution would allow us to assess the statistical evidence to the extent of belief in any one of the parameters is actually zero. I plan to develop a more refined solution and study its theoretical and practical&nbsp;properties.</p>

<h3 id="signal-and-image-processing">Signal and image&nbsp;processing</h3>

<p>Nonparametric cepstrum estimation via optimal risk smoothing<br />
I and my collaborators (Lai et al., 2010) proposed a nonparametric cepstrum estimation procedure that is capable of producing smoother and more accurate cepstrum estimates. The Steins unbiased risk estimation (<span class="caps">SURE</span>) approach is adopted to select the turning parameters. We showed that the use of this <span class="caps">SURE</span> selection method for this problem is asymptotically optimal under suitable regularity&nbsp;conditions.</p>

<h4 id="signal-segmentation">Signal&nbsp;segmentation</h4>

<p>I and my collaborators (Wong et al., 2010) considered the problem of partitioning a non-stationary signal sequence into a set of stationary signal sub-sequences, which can be adequately modeled by a superposition of different sinusoids. We reformulated the problem as a statistical model selection problem, and the minimum description length principle to construct estimators of parameters. These estimators are optimizers of an objective function, which is non-convex and hard to be optimized. A genetic algorithm is developed for solving the difficult optimization&nbsp;problem.</p>

<h4 id="further-research-functional-data-analysis-of-brain-images">Further research: Functional data analysis of brain&nbsp;images</h4>

<p>Functional magnetic resonance imaging (f<span class="caps">MRI</span>) is a well established technique for studying the brain. However, in many situations, such as when the data are acquired in a resting state, it is difficult to know whether the data are truly stationary or if structural breaks are present. In this project, I aim to develop an automatic procedure to detect those breaks by using functional principal component analysis. Due to the computational complexities for estimating the full covariance structure of the three dimensional images, suitable assumptions are required to make computations feasible. Parallel computing technique such as <span class="caps">MPI</span> is expected in the implementation of estimating the covariance&nbsp;structure.</p>

<hr />

<p>Conducting researches is always an excitement to me. I am ready to dedicate myself to be an active and effective&nbsp;researcher.</p>

            </div>         
            <div class="col-xs-12 col-sm-12 col-md-3 col-lg-3 sidebar">
                    <hr class="visible-xs visible-sm">

<div class="reset-box-sizing search">
    <p>Site search by Google:</p> <gcse:searchbox-only></gcse:searchbox-only>
</div>

<div class="github">
Github <i class="fa fa-github-square"></i>:
<a href="http://www.github.com/randy3k" class="btn btn-success btn-xs" target="_blank">
  <span class="glyphicon glyphicon-ok"></span> randy3k
</a>
</div>        
            </div> 
        </div>        
   </div>
   <div class="container"> 
        <hr>               
       <footer>
           <p>&copy; 2014 Randy Lai. Hosted on <a href="//github.com/randy3k">Github</a>, generated by <a href="//jekyllrb.com">Jekyll</a> and themed by <a href="//getbootstrap.com">Bootstrap 3</a>.
</p>
       </footer>   
   </div>
</body>
</html>
